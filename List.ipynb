{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTIrXsK4H31u1ePVh8jmmW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hjhirp/Machine-Learning-Extra/blob/main/List.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O37wzDcshejS"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#X_n_temp1=X[0:400,:]\n",
        "#X_train=np.zeros((X_n_temp1.shape[0],X_n_temp1.shape[1]+1))\n",
        "#X_train[:,0]=np.ones((X_n_temp1.shape[0]))\n",
        "#X_train[:,1:]=X_n_temp1\n",
        "# Linear Regression using mathemaical formula\n",
        "#formula-->\n",
        "#theta = np.random.uniform(0,1,size=(X_train.shape[1]))\n",
        "#alpha = 0.01\n",
        "#j_theta= np.zeros(nits)\n",
        "#for i : 0 nits\n",
        "  #update = np.zeros(X_train.shape[1])\n",
        "  #y_pred = np.dot(X_train, theta)\n",
        "  #error = y_pred - y_train\n",
        "  #for j: n #(n=X_train.shape[1] m=X_train.shape[0])\n",
        "    #update= np.sum(error*(X_train.T)[j])\n",
        "  #theta = theta - 1/m*alpha*update\n",
        "  #j_theta[i]=np.sum(error**2)/(2*m)\n",
        "  #print(\"theta\",theta)\n",
        "\n",
        "#plt.plot(np.arrange(0,1000),j_theta,label=\"0.01\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqSdP83TqOGo"
      },
      "source": [
        "#Scaling\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "#scaler = StandardScaler()\n",
        "#scaler.fit(X_train[:,1:])\n",
        "#X_train[:,1:] = scaler.transform(X_train[:,1:])\n",
        "#X_test[:,1:] = scaler.transform(X_test[:,1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRzSgndZks6a"
      },
      "source": [
        "# Normal method --. (X.T*X)-1*X.T*Y\n",
        "#theta = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(Y)\n",
        "#ypred = theta.dot(y_test)\n",
        "# MSE = metrics.mean_square_error(y_pred= y_pred,y_true= y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVM-LhQClDBa"
      },
      "source": [
        "# Regularistion -->\n",
        "#define -> lamda --> large value\n",
        "#Linear regression -->\n",
        "#theta[0] = theta[0] - i/m*alpha*update[0]\n",
        "#theta[1:] = theta[1:]*(1-alpha*lamda/m)-i/m*alpha*update[1:]\n",
        "## MSE = metrics.mean_square_error(y_pred= y_pred,y_true= y_test)\n",
        "#Normal method -->\n",
        "#reg_matrix = np.zeros((X_train.shape[1],X_train.shape[1]))\n",
        "#lamda = 10000\n",
        "#for i; 1 X_train.shape[1]:\n",
        "#reg_matrix[i][i]=1 || ahiyaj lamda kari dav to?\n",
        "#Reg_matrix_lamda=reg_matrix.dot(lamda)\n",
        "#theta = np.linalg.inv(np.add((X_train.T.dot(X_train)),Reg_matrix_lamda)).dot(X_train.T).dot(y_train)\n",
        "#ypred = X_test.dot(theta)\n",
        "#MSE = matrics.mean_square_error(y_pred=y_pred, y_true = y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDiuKEhvpQJT"
      },
      "source": [
        "#KNN\n",
        "#from sklearn import neighbors\n",
        "#SPLIT THE DATA\n",
        "#weights = distance / uniform\n",
        "#clf = neighbors.KNeighborClassifier(no_of_neighbors , weights)\n",
        "#train test classification matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nosb8hq7u50q"
      },
      "source": [
        "#Naive Bayes\n",
        "#from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "#clq = GaussianNB() if continuos database\n",
        "#clq = BernoulliNB() if discrete but binomial output class\n",
        "#clq = Multinomial() if discrete and not binomial\n",
        "#fit predict classification matrix\n",
        "#use countvectorizer for bernoulli and multinomial\n",
        "#count_vector= CountVectorizer()\n",
        "#count_vector.fit(X_train)\n",
        "#X_train_dtm= count_vector.transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs83ddGy5-Bm"
      },
      "source": [
        "#SVM -->\n",
        "#sns.boxplot(x=\"xname\",y=\"yname\",data=df)\n",
        "#from sklearn.svm import SVC\n",
        "#clq = SVC() // parameters : kernel: linear(default), poly, rbf, sigmoid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auuwggch6zc7"
      },
      "source": [
        "#decision tree\n",
        "#from sklearn.tree import plot_tree , DecisionTreeClassifier\n",
        "#parameters criterion = gini // entropy || max_depth\n",
        "#clf= DecisionTreeClassifier(criterion=\"gini\", max_depth=number)\n",
        "#fit predict classification matrix\n",
        "#plt.figure(figsize=(10,10))\n",
        "#plot_tree(clq, filled=\"true\", feature_name= list of features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngKHViWf8A8C"
      },
      "source": [
        "#Clustering\n",
        "#1. Boxplot see SVM\n",
        "#2. from sklearn.cluster import KMeans\n",
        "#for i: 1 11: ## for finding right number of clusters elbow method\n",
        "#parameters = n_cluster=number, init = 'k-means++' (to make it faster), max_iter=number, n_init = number(number of times kmeans runs with different centroids)\n",
        "#if i cant remember all just run n_clusters and random_state\n",
        "##kmeans = KMeans(n_clusters=i,init = 'k-means++', max_iter =300, n_init =10, random_state =0)\n",
        "##kmeans.fit(X)\n",
        "##wcss.append(kmeans.interia_) #Sum of squared distances of samples to their closest cluster center, weighted by the sample weights if provided.\n",
        "\n",
        "#plt.plot(range(1,11),wcss)\n",
        "#plt.title('The Elbow Method')\n",
        "#plt.xlabel('Number of cluster')\n",
        "#plt.ylabel('WCSS')\n",
        "#plt.show()\n",
        "\n",
        "#kmeans = KMeans(n_clusters=3,init = 'k-means++', max_iter =300, n_init =10, random_state =0)\n",
        "#y_kmeans = kmeans.fit_predict(X)\n",
        "\n",
        "#temp = np.array([[5.7,3.0,4.2,1.2]])\n",
        "#print(y_temp)\n",
        "\n",
        "#plt.figure(figure=(10,10))\n",
        "#plt.scatter(X[y_kmeans == 0,0], X[y_kmeans == 0,1], s = 100, c='lightgreen', label = 'Iris-setosa')\n",
        "#plt.scatter(X[y_kmeans == 1,0], X[y_kmeans == 1,1], s = 100, c='blue', label = 'Iris-versicolour')\n",
        "#plt.scatter(X[y_kmeans == 2,0], X[y_kmeans == 2,1], s = 100, c='red', label = 'Iris-virginica')\n",
        "\n",
        "#plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],s=100,c='black',label='Centroids')\n",
        "#plt.legends()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBgZmyT69fz9"
      },
      "source": [
        "#AND OR IMPLEMENTATION IN PERCEPTRON MODEL\n",
        "#def step_function(x):\n",
        "  #if x>0:\n",
        "    #return 1\n",
        "  #if x<0:\n",
        "    #return 0\n",
        "#\n",
        "#def model(x,w,b):\n",
        "  #n1 = w*x+b\n",
        "  #o1 = step_function(n1)\n",
        "  #return o1\n",
        "#\n",
        "#def AND_model(x):\n",
        "  #w = np.array([1,1])\n",
        "  #b=-1.5 // -1 for or\n",
        "  #return model(x,w,b)\n",
        "#\n",
        "#input=[[0,0],[0,1],[1,0],[1,1]]\n",
        "#for i in input:\n",
        "  #print(\"{} AND {} = {}\".format(i[0],i[1],AND_model(i)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo8xQDbvCRwu"
      },
      "source": [
        "#ANN BACKPROPAGATION\n",
        "# data = [[0,0,1,1],[0,1,0,1]]\n",
        "# X = np.array(data)\n",
        "# result_and = [[0,0,0,1]]\n",
        "# result_or = [[0,1,1,1]]\n",
        "# result_xor = [[0,1,1,0]]\n",
        "\n",
        "# ANN Model - Backpropagation\n",
        "# Implementation\n",
        "\n",
        "# Y = np.array(result_xor)\n",
        "\n",
        "# def activate(x):\n",
        "#     return 1/(1+np.exp(-x))\n",
        "\n",
        "# def intialize_params(inputfeatures , hiddenneurons , outputfeatures):\n",
        "#     W1=np.random.randn(hiddenneurons, inputfeatures)\n",
        "#     W2=np.random.randn(outputfeatures, hiddenneurons)\n",
        "#     b1=np.zeros((hiddenneurons,1))\n",
        "#     b2=np.zeros((outputfeatures,1))\n",
        "\n",
        "#     params = {\n",
        "#         \"W1\":W1,\n",
        "#         \"W2\":W2,\n",
        "#         \"b1\":b1,\n",
        "#         \"b2\":b2,\n",
        "#     }\n",
        "#     return params\n",
        "\n",
        "# def forward(X, Y, params):\n",
        "#     n = X.shape[1]\n",
        "#     W1 = params[\"W1\"]\n",
        "#     W2 = params[\"W2\"]\n",
        "#     b1 = params[\"b1\"]\n",
        "#     b2 = params[\"b2\"]\n",
        "\n",
        "#     Z1= np.dot(W1,X)+b1\n",
        "#     A1= activate(Z1)\n",
        "#     Z2= np.dot(W2,A1)+b2\n",
        "#     A2= activate(Z2)\n",
        "\n",
        "#     cache = (Z1,A1,W1,b1, Z2,A2,W2,b2)\n",
        "#     logprobs = np.multiply(np.log(A2), Y)+ np.multiply(np.log(1-A2),(1-Y))\n",
        "#     cost = -np.sum(logprobs)/n\n",
        "#     return cost, cache, A2\n",
        "\n",
        "# def backprop(X ,Y, cache):\n",
        "#     n = X.shape[1]\n",
        "#     (Z1,A1,W1,b1, Z2,A2,W2,b2)= cache\n",
        "\n",
        "#     dz2= A2-Y\n",
        "#     dW2= np.dot(dz2,A1.T)/n\n",
        "#     db2= np.sum(dz2,axis=1, keepdims=True)\n",
        "\n",
        "#     dA1= np.dot(W2.T, dz2)\n",
        "#     dz1= np.multiply(dA1, A1*(1- A1))\n",
        "\n",
        "#     dW1= np.dot(dz1,X.T)/n\n",
        "#     db1= np.sum(dz1,axis = 1,keepdims = True)/n\n",
        "\n",
        "#     gradient= {\"dZ2\": dz2, \"dW2\": dW2, \"db2\": db2,\n",
        "#                  \"dZ1\": dz1, \"dW1\": dW1, \"db1\": db1}\n",
        "#     return gradient\n",
        "\n",
        "# def update_params(params,gradient,Lr):\n",
        "#     params[\"W1\"]= params[\"W1\"]-Lr*gradient[\"dW1\"]\n",
        "#     params[\"W2\"]= params[\"W2\"]-Lr*gradient[\"dW2\"]\n",
        "#     params[\"b1\"]= params[\"b1\"]-Lr*gradient[\"db1\"]\n",
        "#     params[\"b2\"]= params[\"b2\"]-Lr*gradient[\"db2\"]\n",
        "#     return params\n",
        "\n",
        "# hiddenneurons = 2\n",
        "# inputfeatures= X.shape[0]\n",
        "# outputfeatures= Y.shape[0]\n",
        "# params = intialize_params(inputfeatures, hiddenneurons, outputfeatures)\n",
        "# epochs= 100000\n",
        "# Lr= 0.01\n",
        "# losses = np.zeros((epochs,1))\n",
        "\n",
        "# for i in range(epochs):\n",
        "#     losses[i,0], cache, A2 = forward(X,Y,params)\n",
        "#     gradient = backprop(X, Y,cache)\n",
        "#     param = update_params(params,gradient,Lr)\n",
        "\n",
        "# plt.grid(True)\n",
        "# plt.plot(losses)\n",
        "# plt.xlabel(\"EPOCHS\")\n",
        "# plt.ylabel(\"Loss value\")\n",
        "# plt.show()\n",
        "\n",
        "# X_new = np.array([[1, 1, 0, 0], [0, 1, 0, 1]])\n",
        "# # print(X)\n",
        "# _, _, A2 = forward(X_new, Y, params)\n",
        "# print(A2)\n",
        "# prediction = np.zeros((A2.size))\n",
        "\n",
        "# for a in A2:\n",
        "#     for i in range(4):\n",
        "#         if(a[i]>0.5):\n",
        "#             prediction[i]=1.0\n",
        "\n",
        "# print(prediction)\n",
        "\n",
        "# [[0.98458535 0.01268285 0.01502962 0.986204  ]]\n",
        "# [1. 0. 0. 1.]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdAD19vkEHjW"
      },
      "source": [
        "#ANN SKLEARN MLP\n",
        "#X= np.array([[1,1],[1,0],[0,1],[0,0]])\n",
        "#X_new= np.array([[0,1],[1,1],[0,0],[1,0]])\n",
        "#results_xor=[0,1,1,0]\n",
        "#Y=np.array(result_xor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ILxWi7Tt0ra"
      },
      "source": [
        "https://www.kaggle.com/hirparaharshal/evaluation-of-car-dataset-with-multiple-classifers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MSeShrOt2ep"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uQDbfV0EgVA"
      },
      "source": [
        "# from sklearn.neural_network import MLPClassifier\n",
        "# clf = MLPClassifier(solver = \"lbgfs\", alpha = 0.00001, hidden_layer_size(5,4), random_state=1)\n",
        "# clf.fit(X,Y)\n",
        "# y_pred =clf.predict(X_new)\n",
        "# print(Y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYaPe0xBFT-E"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}