{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdjXufixIrfwojue0Vo0rr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hjhirp/Machine-Learning-Extra/blob/main/KnnClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWfhhgpNZoJP",
        "outputId": "8a97fbc1-c59d-4c90-f1b2-050b9c365ff5"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy\n",
        "from sklearn import neighbors, datasets, metrics #Notice neighbors\n",
        "X, y=datasets.load_iris(return_X_y=True) #Loading the Iris Dataset\n",
        "X_train=X[range(0,150,2),:]\n",
        "y_train=y[range(0,150,2)]\n",
        "X_test=X[range(1,150,2),:]\n",
        "y_test=y[range(1,150,2)]\n",
        "#variable for specifying number of nearest neighbors to be used\n",
        "n_neighbors=numpy.arange(1,31)\n",
        "weights='uniform' #or weights='distance'\n",
        "#creating instance of a classifier\n",
        "acc1 = []\n",
        "for i in range(len(n_neighbors)):\n",
        "  print(\"#############################################\")\n",
        "  print(i)\n",
        "  clf = neighbors.KNeighborsClassifier(n_neighbors[i], weights)\n",
        "  # other argument is metric (default is 'minkowski'. There are many other possibilities including 'euclidean')\n",
        "  #Other useful argument is p which controls the power of minkowski distance. Default is 2\n",
        "  clf.fit(X_train, y_train)\n",
        "  prediction = clf.predict(X_test) #predict using the learnt classifier\n",
        "  print(\"############### Predictions #################\")\n",
        "  print(prediction)\n",
        "  print(\"#############################################\")\n",
        "  acc1.append(metrics.accuracy_score(y_test, prediction, normalize=True))\n",
        "  print(\"Accuracy = \", acc1[i])\n",
        "  print(metrics.classification_report(y_test, prediction))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#############################################\n",
            "0\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "#############################################\n",
            "1\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.93      1.00      0.96        25\n",
            "           2       1.00      0.92      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.98      0.97      0.97        75\n",
            "weighted avg       0.98      0.97      0.97        75\n",
            "\n",
            "#############################################\n",
            "2\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.96      0.92      0.94        25\n",
            "           2       0.92      0.96      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "#############################################\n",
            "3\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9466666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.89      0.96      0.92        25\n",
            "           2       0.96      0.88      0.92        25\n",
            "\n",
            "    accuracy                           0.95        75\n",
            "   macro avg       0.95      0.95      0.95        75\n",
            "weighted avg       0.95      0.95      0.95        75\n",
            "\n",
            "#############################################\n",
            "4\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9866666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       1.00      0.96      0.98        25\n",
            "           2       0.96      1.00      0.98        25\n",
            "\n",
            "    accuracy                           0.99        75\n",
            "   macro avg       0.99      0.99      0.99        75\n",
            "weighted avg       0.99      0.99      0.99        75\n",
            "\n",
            "#############################################\n",
            "5\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.96      0.96      0.96        25\n",
            "           2       0.96      0.96      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.97      0.97      0.97        75\n",
            "weighted avg       0.97      0.97      0.97        75\n",
            "\n",
            "#############################################\n",
            "6\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9866666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       1.00      0.96      0.98        25\n",
            "           2       0.96      1.00      0.98        25\n",
            "\n",
            "    accuracy                           0.99        75\n",
            "   macro avg       0.99      0.99      0.99        75\n",
            "weighted avg       0.99      0.99      0.99        75\n",
            "\n",
            "#############################################\n",
            "7\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.96      0.96      0.96        25\n",
            "           2       0.96      0.96      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.97      0.97      0.97        75\n",
            "weighted avg       0.97      0.97      0.97        75\n",
            "\n",
            "#############################################\n",
            "8\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9866666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       1.00      0.96      0.98        25\n",
            "           2       0.96      1.00      0.98        25\n",
            "\n",
            "    accuracy                           0.99        75\n",
            "   macro avg       0.99      0.99      0.99        75\n",
            "weighted avg       0.99      0.99      0.99        75\n",
            "\n",
            "#############################################\n",
            "9\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 2 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.92\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.83      0.96      0.89        25\n",
            "           2       0.95      0.80      0.87        25\n",
            "\n",
            "    accuracy                           0.92        75\n",
            "   macro avg       0.93      0.92      0.92        75\n",
            "weighted avg       0.93      0.92      0.92        75\n",
            "\n",
            "#############################################\n",
            "10\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 2 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.92\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.83      0.96      0.89        25\n",
            "           2       0.95      0.80      0.87        25\n",
            "\n",
            "    accuracy                           0.92        75\n",
            "   macro avg       0.93      0.92      0.92        75\n",
            "weighted avg       0.93      0.92      0.92        75\n",
            "\n",
            "#############################################\n",
            "11\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.92\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.81      1.00      0.89        25\n",
            "           2       1.00      0.76      0.86        25\n",
            "\n",
            "    accuracy                           0.92        75\n",
            "   macro avg       0.94      0.92      0.92        75\n",
            "weighted avg       0.94      0.92      0.92        75\n",
            "\n",
            "#############################################\n",
            "12\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9466666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.86      1.00      0.93        25\n",
            "           2       1.00      0.84      0.91        25\n",
            "\n",
            "    accuracy                           0.95        75\n",
            "   macro avg       0.95      0.95      0.95        75\n",
            "weighted avg       0.95      0.95      0.95        75\n",
            "\n",
            "#############################################\n",
            "13\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.83      1.00      0.91        25\n",
            "           2       1.00      0.80      0.89        25\n",
            "\n",
            "    accuracy                           0.93        75\n",
            "   macro avg       0.94      0.93      0.93        75\n",
            "weighted avg       0.94      0.93      0.93        75\n",
            "\n",
            "#############################################\n",
            "14\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.92\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.83      0.96      0.89        25\n",
            "           2       0.95      0.80      0.87        25\n",
            "\n",
            "    accuracy                           0.92        75\n",
            "   macro avg       0.93      0.92      0.92        75\n",
            "weighted avg       0.93      0.92      0.92        75\n",
            "\n",
            "#############################################\n",
            "15\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.92\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.83      0.96      0.89        25\n",
            "           2       0.95      0.80      0.87        25\n",
            "\n",
            "    accuracy                           0.92        75\n",
            "   macro avg       0.93      0.92      0.92        75\n",
            "weighted avg       0.93      0.92      0.92        75\n",
            "\n",
            "#############################################\n",
            "16\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.92\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.83      0.96      0.89        25\n",
            "           2       0.95      0.80      0.87        25\n",
            "\n",
            "    accuracy                           0.92        75\n",
            "   macro avg       0.93      0.92      0.92        75\n",
            "weighted avg       0.93      0.92      0.92        75\n",
            "\n",
            "#############################################\n",
            "17\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.83      1.00      0.91        25\n",
            "           2       1.00      0.80      0.89        25\n",
            "\n",
            "    accuracy                           0.93        75\n",
            "   macro avg       0.94      0.93      0.93        75\n",
            "weighted avg       0.94      0.93      0.93        75\n",
            "\n",
            "#############################################\n",
            "18\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.92\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.83      0.96      0.89        25\n",
            "           2       0.95      0.80      0.87        25\n",
            "\n",
            "    accuracy                           0.92        75\n",
            "   macro avg       0.93      0.92      0.92        75\n",
            "weighted avg       0.93      0.92      0.92        75\n",
            "\n",
            "#############################################\n",
            "19\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.83      1.00      0.91        25\n",
            "           2       1.00      0.80      0.89        25\n",
            "\n",
            "    accuracy                           0.93        75\n",
            "   macro avg       0.94      0.93      0.93        75\n",
            "weighted avg       0.94      0.93      0.93        75\n",
            "\n",
            "#############################################\n",
            "20\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.83      1.00      0.91        25\n",
            "           2       1.00      0.80      0.89        25\n",
            "\n",
            "    accuracy                           0.93        75\n",
            "   macro avg       0.94      0.93      0.93        75\n",
            "weighted avg       0.94      0.93      0.93        75\n",
            "\n",
            "#############################################\n",
            "21\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.92\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.81      1.00      0.89        25\n",
            "           2       1.00      0.76      0.86        25\n",
            "\n",
            "    accuracy                           0.92        75\n",
            "   macro avg       0.94      0.92      0.92        75\n",
            "weighted avg       0.94      0.92      0.92        75\n",
            "\n",
            "#############################################\n",
            "22\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.92\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.83      0.96      0.89        25\n",
            "           2       0.95      0.80      0.87        25\n",
            "\n",
            "    accuracy                           0.92        75\n",
            "   macro avg       0.93      0.92      0.92        75\n",
            "weighted avg       0.93      0.92      0.92        75\n",
            "\n",
            "#############################################\n",
            "23\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9066666666666666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.80      0.96      0.87        25\n",
            "           2       0.95      0.76      0.84        25\n",
            "\n",
            "    accuracy                           0.91        75\n",
            "   macro avg       0.92      0.91      0.91        75\n",
            "weighted avg       0.92      0.91      0.91        75\n",
            "\n",
            "#############################################\n",
            "24\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.86      0.96      0.91        25\n",
            "           2       0.95      0.84      0.89        25\n",
            "\n",
            "    accuracy                           0.93        75\n",
            "   macro avg       0.94      0.93      0.93        75\n",
            "weighted avg       0.94      0.93      0.93        75\n",
            "\n",
            "#############################################\n",
            "25\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9066666666666666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.80      0.96      0.87        25\n",
            "           2       0.95      0.76      0.84        25\n",
            "\n",
            "    accuracy                           0.91        75\n",
            "   macro avg       0.92      0.91      0.91        75\n",
            "weighted avg       0.92      0.91      0.91        75\n",
            "\n",
            "#############################################\n",
            "26\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 1 2 2 1 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.86      0.96      0.91        25\n",
            "           2       0.95      0.84      0.89        25\n",
            "\n",
            "    accuracy                           0.93        75\n",
            "   macro avg       0.94      0.93      0.93        75\n",
            "weighted avg       0.94      0.93      0.93        75\n",
            "\n",
            "#############################################\n",
            "27\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 1 1 2 1 2 2 2 2 2 2 2 2 2 2\n",
            " 1]\n",
            "#############################################\n",
            "Accuracy =  0.9066666666666666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.80      0.96      0.87        25\n",
            "           2       0.95      0.76      0.84        25\n",
            "\n",
            "    accuracy                           0.91        75\n",
            "   macro avg       0.92      0.91      0.91        75\n",
            "weighted avg       0.92      0.91      0.91        75\n",
            "\n",
            "#############################################\n",
            "28\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 1 1 2 1 2 2 2 2 2 2 2 2 2 2\n",
            " 1]\n",
            "#############################################\n",
            "Accuracy =  0.9066666666666666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.80      0.96      0.87        25\n",
            "           2       0.95      0.76      0.84        25\n",
            "\n",
            "    accuracy                           0.91        75\n",
            "   macro avg       0.92      0.91      0.91        75\n",
            "weighted avg       0.92      0.91      0.91        75\n",
            "\n",
            "#############################################\n",
            "29\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 1 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
            " 1]\n",
            "#############################################\n",
            "Accuracy =  0.8933333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.77      0.96      0.86        25\n",
            "           2       0.95      0.72      0.82        25\n",
            "\n",
            "    accuracy                           0.89        75\n",
            "   macro avg       0.91      0.89      0.89        75\n",
            "weighted avg       0.91      0.89      0.89        75\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7_KB1IxaFTc",
        "outputId": "3b7d7b55-8694-4207-a74e-ae69767c551a"
      },
      "source": [
        "import numpy\n",
        "from sklearn import neighbors, datasets, metrics #Notice neighbors\n",
        "X, y=datasets.load_iris(return_X_y=True) #Loading the Iris Dataset\n",
        "X_train=X[range(0,150,2),:]\n",
        "y_train=y[range(0,150,2)]\n",
        "X_test=X[range(1,150,2),:]\n",
        "y_test=y[range(1,150,2)]\n",
        "#variable for specifying number of nearest neighbors to be used\n",
        "n_neighbors=numpy.arange(1,31)\n",
        "weights='distance' #or weights='distance'\n",
        "#creating instance of a classifier\n",
        "acc2 = []\n",
        "for i in range(len(n_neighbors)):\n",
        "  print(\"#############################################\")\n",
        "  print(i)\n",
        "  clf = neighbors.KNeighborsClassifier(n_neighbors[i], weights)\n",
        "  # other argument is metric (default is 'minkowski'. There are many other possibilities including 'euclidean')\n",
        "  #Other useful argument is p which controls the power of minkowski distance. Default is 2\n",
        "  clf.fit(X_train, y_train)\n",
        "  prediction = clf.predict(X_test) #predict using the learnt classifier\n",
        "  print(\"############### Predictions #################\")\n",
        "  print(prediction)\n",
        "  print(\"#############################################\")\n",
        "  acc2.append(metrics.accuracy_score(y_test, prediction, normalize=True))\n",
        "  print(\"Accuracy = \", acc2[i])\n",
        "  print(metrics.classification_report(y_test, prediction))\n",
        "  print(metrics.confusion_matrix(y_test, prediction))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#############################################\n",
            "0\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "1\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "2\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.96      0.92      0.94        25\n",
            "           2       0.92      0.96      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 23  2]\n",
            " [ 0  1 24]]\n",
            "#############################################\n",
            "3\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "4\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9866666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       1.00      0.96      0.98        25\n",
            "           2       0.96      1.00      0.98        25\n",
            "\n",
            "    accuracy                           0.99        75\n",
            "   macro avg       0.99      0.99      0.99        75\n",
            "weighted avg       0.99      0.99      0.99        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  0 25]]\n",
            "#############################################\n",
            "5\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9866666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       1.00      0.96      0.98        25\n",
            "           2       0.96      1.00      0.98        25\n",
            "\n",
            "    accuracy                           0.99        75\n",
            "   macro avg       0.99      0.99      0.99        75\n",
            "weighted avg       0.99      0.99      0.99        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  0 25]]\n",
            "#############################################\n",
            "6\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9866666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       1.00      0.96      0.98        25\n",
            "           2       0.96      1.00      0.98        25\n",
            "\n",
            "    accuracy                           0.99        75\n",
            "   macro avg       0.99      0.99      0.99        75\n",
            "weighted avg       0.99      0.99      0.99        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  0 25]]\n",
            "#############################################\n",
            "7\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9866666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       1.00      0.96      0.98        25\n",
            "           2       0.96      1.00      0.98        25\n",
            "\n",
            "    accuracy                           0.99        75\n",
            "   macro avg       0.99      0.99      0.99        75\n",
            "weighted avg       0.99      0.99      0.99        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  0 25]]\n",
            "#############################################\n",
            "8\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9866666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       1.00      0.96      0.98        25\n",
            "           2       0.96      1.00      0.98        25\n",
            "\n",
            "    accuracy                           0.99        75\n",
            "   macro avg       0.99      0.99      0.99        75\n",
            "weighted avg       0.99      0.99      0.99        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  0 25]]\n",
            "#############################################\n",
            "9\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.96      0.96      0.96        25\n",
            "           2       0.96      0.96      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.97      0.97      0.97        75\n",
            "weighted avg       0.97      0.97      0.97        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  1 24]]\n",
            "#############################################\n",
            "10\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "11\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.96      0.96      0.96        25\n",
            "           2       0.96      0.96      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.97      0.97      0.97        75\n",
            "weighted avg       0.97      0.97      0.97        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  1 24]]\n",
            "#############################################\n",
            "12\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.96      0.96      0.96        25\n",
            "           2       0.96      0.96      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.97      0.97      0.97        75\n",
            "weighted avg       0.97      0.97      0.97        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  1 24]]\n",
            "#############################################\n",
            "13\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.96      0.96      0.96        25\n",
            "           2       0.96      0.96      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.97      0.97      0.97        75\n",
            "weighted avg       0.97      0.97      0.97        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  1 24]]\n",
            "#############################################\n",
            "14\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9466666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.89      0.96      0.92        25\n",
            "           2       0.96      0.88      0.92        25\n",
            "\n",
            "    accuracy                           0.95        75\n",
            "   macro avg       0.95      0.95      0.95        75\n",
            "weighted avg       0.95      0.95      0.95        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  3 22]]\n",
            "#############################################\n",
            "15\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "16\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "17\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "18\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "19\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "20\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "21\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "22\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.92      0.96      0.94        25\n",
            "           2       0.96      0.92      0.94        25\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.96      0.96      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "23\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.93      1.00      0.96        25\n",
            "           2       1.00      0.92      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.98      0.97      0.97        75\n",
            "weighted avg       0.98      0.97      0.97        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 25  0]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "24\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.93      1.00      0.96        25\n",
            "           2       1.00      0.92      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.98      0.97      0.97        75\n",
            "weighted avg       0.98      0.97      0.97        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 25  0]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "25\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.93      1.00      0.96        25\n",
            "           2       1.00      0.92      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.98      0.97      0.97        75\n",
            "weighted avg       0.98      0.97      0.97        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 25  0]\n",
            " [ 0  2 23]]\n",
            "#############################################\n",
            "26\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.96      0.96      0.96        25\n",
            "           2       0.96      0.96      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.97      0.97      0.97        75\n",
            "weighted avg       0.97      0.97      0.97        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  1 24]]\n",
            "#############################################\n",
            "27\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.96      0.96      0.96        25\n",
            "           2       0.96      0.96      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.97      0.97      0.97        75\n",
            "weighted avg       0.97      0.97      0.97        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  1 24]]\n",
            "#############################################\n",
            "28\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9733333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.96      0.96      0.96        25\n",
            "           2       0.96      0.96      0.96        25\n",
            "\n",
            "    accuracy                           0.97        75\n",
            "   macro avg       0.97      0.97      0.97        75\n",
            "weighted avg       0.97      0.97      0.97        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 24  1]\n",
            " [ 0  1 24]]\n",
            "#############################################\n",
            "29\n",
            "############### Predictions #################\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
            " 2]\n",
            "#############################################\n",
            "Accuracy =  0.9333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       0.88      0.92      0.90        25\n",
            "           2       0.92      0.88      0.90        25\n",
            "\n",
            "    accuracy                           0.93        75\n",
            "   macro avg       0.93      0.93      0.93        75\n",
            "weighted avg       0.93      0.93      0.93        75\n",
            "\n",
            "[[25  0  0]\n",
            " [ 0 23  2]\n",
            " [ 0  3 22]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZXs06DjeSID",
        "outputId": "953a89e1-7a22-4961-8c05-2d49be322181"
      },
      "source": [
        "print(\"Unweighted\")\n",
        "for i in n_neighbors:\n",
        "  print(\" n = {} accuracy = {}\".format(i,acc1[i-1]))\n",
        "print(\"#############################################\")\n",
        "print(\"Distance\")\n",
        "for i in n_neighbors:\n",
        "  print(\" n = {} accuracy = {}\".format(i,acc2[i-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unweighted\n",
            " n = 1 accuracy = 0.96\n",
            " n = 2 accuracy = 0.9733333333333334\n",
            " n = 3 accuracy = 0.96\n",
            " n = 4 accuracy = 0.9466666666666667\n",
            " n = 5 accuracy = 0.9866666666666667\n",
            " n = 6 accuracy = 0.9733333333333334\n",
            " n = 7 accuracy = 0.9866666666666667\n",
            " n = 8 accuracy = 0.9733333333333334\n",
            " n = 9 accuracy = 0.9866666666666667\n",
            " n = 10 accuracy = 0.92\n",
            " n = 11 accuracy = 0.92\n",
            " n = 12 accuracy = 0.92\n",
            " n = 13 accuracy = 0.9466666666666667\n",
            " n = 14 accuracy = 0.9333333333333333\n",
            " n = 15 accuracy = 0.92\n",
            " n = 16 accuracy = 0.92\n",
            " n = 17 accuracy = 0.92\n",
            " n = 18 accuracy = 0.9333333333333333\n",
            " n = 19 accuracy = 0.92\n",
            " n = 20 accuracy = 0.9333333333333333\n",
            " n = 21 accuracy = 0.9333333333333333\n",
            " n = 22 accuracy = 0.92\n",
            " n = 23 accuracy = 0.92\n",
            " n = 24 accuracy = 0.9066666666666666\n",
            " n = 25 accuracy = 0.9333333333333333\n",
            " n = 26 accuracy = 0.9066666666666666\n",
            " n = 27 accuracy = 0.9333333333333333\n",
            " n = 28 accuracy = 0.9066666666666666\n",
            " n = 29 accuracy = 0.9066666666666666\n",
            " n = 30 accuracy = 0.8933333333333333\n",
            "#############################################\n",
            "Distance\n",
            " n = 1 accuracy = 0.96\n",
            " n = 2 accuracy = 0.96\n",
            " n = 3 accuracy = 0.96\n",
            " n = 4 accuracy = 0.96\n",
            " n = 5 accuracy = 0.9866666666666667\n",
            " n = 6 accuracy = 0.9866666666666667\n",
            " n = 7 accuracy = 0.9866666666666667\n",
            " n = 8 accuracy = 0.9866666666666667\n",
            " n = 9 accuracy = 0.9866666666666667\n",
            " n = 10 accuracy = 0.9733333333333334\n",
            " n = 11 accuracy = 0.96\n",
            " n = 12 accuracy = 0.9733333333333334\n",
            " n = 13 accuracy = 0.9733333333333334\n",
            " n = 14 accuracy = 0.9733333333333334\n",
            " n = 15 accuracy = 0.9466666666666667\n",
            " n = 16 accuracy = 0.96\n",
            " n = 17 accuracy = 0.96\n",
            " n = 18 accuracy = 0.96\n",
            " n = 19 accuracy = 0.96\n",
            " n = 20 accuracy = 0.96\n",
            " n = 21 accuracy = 0.96\n",
            " n = 22 accuracy = 0.96\n",
            " n = 23 accuracy = 0.96\n",
            " n = 24 accuracy = 0.9733333333333334\n",
            " n = 25 accuracy = 0.9733333333333334\n",
            " n = 26 accuracy = 0.9733333333333334\n",
            " n = 27 accuracy = 0.9733333333333334\n",
            " n = 28 accuracy = 0.9733333333333334\n",
            " n = 29 accuracy = 0.9733333333333334\n",
            " n = 30 accuracy = 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "rvBPjf36dejG",
        "outputId": "e2cd692e-b8f1-4ed6-917e-a05235833fae"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(n_neighbors,acc1,label=\"Uniform\",marker='X')\n",
        "plt.plot(n_neighbors,acc2,label=\"Distance\",marker='*')\n",
        "plt.grid(True)\n",
        "plt.legend(loc=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1b81750590>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X50XVdgErxkU"
      },
      "source": [
        "### For smaller values(<10) unweighted KNN can be used as it has better accuracy but when it come to large values(>10) distance KNN will have better and also stable accuracy compared to unweighted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs1Q_4ji-cjT"
      },
      "source": [
        "# pip install mglearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83PpLrfJd8BA"
      },
      "source": [
        "# import mglearn\n",
        "# mglearn.plots.plot_knn_classification(n_neighbors=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILK-HFgF_RWt"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}